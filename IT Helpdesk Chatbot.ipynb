{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cf9a38b",
   "metadata": {},
   "source": [
    "# ðŸ¤– IT Helpdesk Chatbot (NLP Project)\n",
    "\n",
    "Improved version with:\n",
    "- Train/Test split\n",
    "- Lightweight spaCy model\n",
    "- Model saving\n",
    "- Cleaner preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b5c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2e8cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"intents.json\") as file:\n",
    "    data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c430d417",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z ]\", \"\", text)\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc if not token.is_punct])\n",
    "\n",
    "patterns = []\n",
    "labels = []\n",
    "responses = []\n",
    "classes = []\n",
    "\n",
    "for intent in data[\"intents\"]:\n",
    "    for pattern in intent[\"patterns\"]:\n",
    "        patterns.append(preprocess(pattern))\n",
    "        labels.append(intent[\"tag\"])\n",
    "    responses.append(intent[\"responses\"])\n",
    "    classes.append(intent[\"tag\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ba283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(patterns)\n",
    "sequences = tokenizer.texts_to_sequences(patterns)\n",
    "padded = pad_sequences(sequences)\n",
    "\n",
    "label_index = {label: idx for idx, label in enumerate(set(labels))}\n",
    "y = [label_index[label] for label in labels]\n",
    "y = to_categorical(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    padded, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14f0db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(y.shape[1], activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c115251",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=35,\n",
    "    batch_size=8,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88b1254",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save(\"chatbot_model.h5\")\n",
    "print(\"Model saved successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0800731",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
